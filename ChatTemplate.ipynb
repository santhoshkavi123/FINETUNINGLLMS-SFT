{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6b63ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing in /usr/local/lib/python3.12/dist-packages (3.7.4.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install typing transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20efc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba7b01",
   "metadata": {},
   "source": [
    "# Base Models vs Instruct Models\n",
    "\n",
    "A base model is trained on raw text data to predict the next token, while an instruct model is fine-tuned specifically to follow instructions and engage in conversations. For example, SmolLM2-135M is a base model, while SmolLM2-135M-Instruct is its instruction-tuned variant.\n",
    "\n",
    "Instruction Tuned models are trained to follow a specific conversational structure, making them more suitable for chatbot applications. Moreover instruct models can handle complex interactions, including toll use, mutimodel inputs and function calling.\n",
    "\n",
    "When using an instruct model, always verify you're using the correct chat template format. Using the wrong template can result in poor model performance or unexpected behaviour. The easiest way to ensure this is to check the model tokenizer configuration on the Hub. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a036e4f",
   "metadata": {},
   "source": [
    "## Common Template Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a599cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'Hello!'},\n",
       " {'role': 'assistant', 'content': 'Hi! How can I help you today?'},\n",
       " {'role': 'user', 'content': \"What's the weather?\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role':\"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "    {\"role\": \"user\", \"content\":\"Hello!\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"Hi! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather?\"}\n",
    "]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba5b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is the ChatML Template used in models like SmolLM2 and Qwen2\n",
    "\n",
    "# <|im_start|>system\n",
    "# You are a helpful assistant.<|im_end|>\n",
    "# <|im_start|>user\n",
    "# Hello!<|im_end|>\n",
    "# <|im_start|>assistant\n",
    "# Hi! How can I help you today?<|im_end|>\n",
    "# <|im_start|>user\n",
    "# What's the weather?<|im_start|>assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d928098",
   "metadata": {},
   "source": [
    "## So each and every instruct model follows different varitions. Transformers library helps us handle these variations automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c683495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will use different templates automatically\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "smol_tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "\n",
    "# Each will format according to its model's template\n",
    "mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "408e7c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] You are a helpful assistant.\n",
      "\n",
      "Hello! [/INST] Hi! How can I help you today?</s> [INST] What's the weather? [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(mistral_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "480f3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful assistant.</s>\n",
      "<|user|>\n",
      "Hello!</s>\n",
      "<|assistant|>\n",
      "Hi! How can I help you today?</s>\n",
      "<|user|>\n",
      "What's the weather?</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qwen_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1404ed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hello!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "What's the weather?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(smol_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e56a9",
   "metadata": {},
   "source": [
    "## For multimodel conversations, chat templates can include image references or base64-encoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3000a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful vision assistant that can analyze images.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "            {\"type\": \"image\", \"image_url\": \"https://example.com/image.jpg\"},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4d81b",
   "metadata": {},
   "source": [
    "When working with chat templates, follow these key practices:\n",
    "\n",
    "* Consistent Formatting: Always use the same template format throughout your application\n",
    "* Clear Role Definition: Clearly specify roles (system, user, assistant, tool) for each message\n",
    "* Context Management: Be mindful of token limits when maintaining conversation history\n",
    "* Error Handling: Include proper error handling for tool calls and multimodal inputs\n",
    "* Validation: Validate message structure before sending to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff896",
   "metadata": {},
   "source": [
    "# Converting a Dataset values into a Chat Templates format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efdd7a4",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d437451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a9931bd9024664b45a8628eb563790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/smol-summarize/train-00000-of-00001(…):   0%|          | 0.00/119M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e25dc624f81492b884c6bee287301db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/smol-summarize/test-00000-of-00001.(…):   0%|          | 0.00/6.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564c7d68f6754faeb3a4410f48dc0d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/96356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019a194df5fb48c2983b704b42e162dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 96356\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 5072\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-summarize\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5642940f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Extract and present the main key point of the input text in one very short sentence, including essential details like dates or locations if necessary.',\n",
       "  'role': 'system'},\n",
       " {'content': \"Hi Sarah,\\n\\nI hope you're doing well! I wanted to reach out because I've been struggling with a student in my class who is significantly behind in reading comprehension. I remember you mentioning some effective strategies during our last conversation, and I was wondering if you could share some resources or tips that might help me support this student better.\\n\\nAny advice would be greatly appreciated! Let me know if you have time to chat further about this.\\n\\nBest,\\nEmily\",\n",
       "  'role': 'user'},\n",
       " {'content': 'Emily is seeking advice on strategies for a struggling reader in her class.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08148d9e",
   "metadata": {},
   "source": [
    "## 2. Create a processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7ce1daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2ca0dfc8ac4e518152247498a9c112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/96356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_chatml(message):\n",
    "    return {\n",
    "        \"messages\":[\n",
    "            {\"role\":message[\"messages\"][1][\"role\"], \"content\": message[\"messages\"][1][\"content\"]},\n",
    "            {\"role\":message[\"messages\"][2][\"role\"], \"content\": message[\"messages\"][2][\"content\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "train = dataset[\"train\"].map(convert_to_chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ab75de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"Hi Sarah,\\n\\nI hope you're doing well! I wanted to reach out because I've been struggling with a student in my class who is significantly behind in reading comprehension. I remember you mentioning some effective strategies during our last conversation, and I was wondering if you could share some resources or tips that might help me support this student better.\\n\\nAny advice would be greatly appreciated! Let me know if you have time to chat further about this.\\n\\nBest,\\nEmily\",\n",
       "  'role': 'user'},\n",
       " {'content': 'Emily is seeking advice on strategies for a struggling reader in her class.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb5d59",
   "metadata": {},
   "source": [
    "Above, we have extracted just the messages related role user and assistant "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
